---
layout: post
title: "[Kafka] Kafka 개념"
date: 2023-08-22 23:06:00 +09:00
categories: [Data, Kafka]
tags: [Data, Kafka]
comments: true
---

## 개념

Kafka 기본 구조

### Kafka란?

**카프카(Kafka)**는 **파이프라인**, **스트리밍 분석,** **데이터 통합** 및 미션 크리티컬 애플리케이션을 위해 설계된 **고성능 분산 이벤트 스트리밍 플랫폼 입니다**.

**Pub-Sub 모델의 메시지 큐** 형태로 동작하며 **분산환경에 특화**되어 있습니다.

- 부가설명 (상세)

  카프카는 분산 메세징 시스템 or 이벤트 스트리밍 시스템 또는 미들웨어라 불리며

  **메세지(데이터)의 송신자와 수신자의 중개를 하는 시스템 입니다**.

  대용량, 대규모 메세지 데이터를 빠르게 처리하도록 개발된 송신자(Publisher)와 수신자(Consumer)의 중개하는 역할을 합니다.

  또한 **분산 환경에 특화**되는 특징을 가지고 있습니다.

  **MQTT or RabbitMQ**는 메세지(데이터) 저장보다는 **실시간 메시징 및 통신**에 더 중점을 두고 있습니다. 즉 **데이터 소비가 이루어지면 데이터가 지워지는 특성**이 있습니다

  다만 **Kafka**는 **바로 지워지지 않고** **디스크에 유지**되고 있어 **복원**은 물론 소비된 메세지 추적 개념의 offset, commit이 있어 **장애가 난 시점을 찾기 쉬우며** 보다 쉽게 대응을 할 수 있습니다.

### 카프카의 특징

1. **대량의 데이터를 고속으로 처리할 수 있다.**

    빅데이터, IoT와 같은 데이터가 많을 경우를 고려하면 대량의 데이터를 고속으로 처리할 수 있는 것은 매우 중요합니다. **Kafka는 Pub-Sub 메시징 모델과 약간 다른 구성**이 되어 있고, **여러 Broker 구성**으로 되어 있어 스케일 아웃을 하기 쉽다. 스케일 아웃의 용이성은 빠른 처리 향상에 직결됩니다.

2. **자유로운 타이밍에서의 데이터 이용이 가능하다.**

    앞에서 언급한 `고속` 이라고 하는 것은 real-time 처리를 말하지만, 반드시 real-time 처리 뿐만은 아니라는 점. Kafka에 접속되는 Consumer는 다양한 종류의 처리 및 일괄 처리를 하는 경우도 있다. 또한, 데이터도 곧바로 사용하는 것은 아니고, Broker내에서 장기간에 걸쳐 보존이 필요한 경우가 있지만, **Kafka에서는 데이터를 메모리상 뿐만이 아니라 디스크에 기입하는 것으로 영속적인 보존을 가능하게 한다**. 이렇게 함으로써 데이터를 자유롭게 사용할 수 있습니다.

3. 고속성**을 유지하면서 데이터의 송신 보증이 가능하다.**

    데이터의 전달 보증이라고 하면, 1건씩 데이터에 대한 트랜잭션 처리가 쉬울 수 있다고 생각할 수도 있지만, 이는 실행하면서 고속으로 데이터를 처리한다는 것은 난이도가 매우 높다. 그리고 당연히 도중에 **데이터가 손실**되는 것도 피해야 한다. 가장 엄격한 데이터 전달 보증은 “1건의 데이터를 확실히 1회씩 보내기”(**Exactly at once**)이지만, Kafka에서는 “(중복이어도 상관 없기 때문에) 적어도 1회는 확실하게 데이터를 송신한다”(**At least once**)를 실현함으로써 고속성과 데이터 전달 보증의 균형을 맞추고 있다.

4. **데이터를 송수신하기 위한 API가 충실하다**

    Kafka에 접속되는 Producer/Consumer(Producer는 Pub-Sub 메시징 모델의 Publisher에 해당)는 하나만 있는 것이 아니고, 다른 시스템에 속하고 있는 경우도 많다. 이러한 경우에는 Publisher/Subscriber와 Kafka 사이에 접속용 API가 중요해 진다. 접속 API의 역할을 하는 것으로서 “Kafka Connect”(및 Kafka Connect 접속하는 Connector 플러그인)가 제공되고 있다. API를 사용자 측에서 개발하는 것은 매우 번거롭기 때문에 풍부한 API를 제공하면 개발 효율성을 높이는 데 도움이 된다.

그 밖에 특징들

- Producer와 Consumer의 분리
  - 카프카는 메시징 전송 방식 중 메시지를 보내는 역할과 받는 역할이 완벽하게 분리된 Pub-Sub 방식을 적용한다.
  - 각자의 역할이 완벽하게 분리되면서, 어느 한쪽 시스템에서 문제가 발생하더라도 연쇄작용이 발생할 확률은 매우 낮다.
- 멀티 프로듀서, 멀티 컨슈머
  - 카프카는 하나의 토픽에 여러 프로듀서 또는 컨슈머들이 접근 가능한 구조로 되어있다.
  - 데이터 분석 및 처리 프로세스에서 하나의 데이터를 다양한 용도로 사용하는 요구가 많아지기 시작했고, 멀티 기능 덕분에 이러한 요구를 손쉽게 충족할 수 있다.
- 디스크에 메시지 저장
  - 디스크에 메시지를 저장하고 유지한다.
  - 컨슈머가 메시지를 읽어가더라도 보관 주기 동안 디스크에 메시지를 저장해둔다.
- 확장성
  - 카프카는 확장이 매우 용이하도록 설계되어 있다. 하나의 카프카 클러스터는 3대의 브로커로 시작해 수집 대의 브로커로 확장 가능하다.
  - 확장 작업은 카프카 서비스의 중단 없이 온라인 상태에서 작업이 가능하다.
- 높은 성능
  - 고성능을 유지하기 위해 카프카는 내부적으로 분산 처리, 배치 처리 등 다양한 기법을 사용하고 있다.

### 카프카의 ACK

0 : 프로듀서는 서버로부터 어떠한 ack도 기다리지 않음. 유실율 높으나 높은 처리량

1 : 리더는 데이터를 기록, 모든 팔로워는 확인하지 않음

-1(또는 all) : 모든 ISR 확인. 무손실

### 카프카의 Broker

카프카 브로커는 프로듀서로부터 메시지를 전달받고, 다시 이를 컨슈머로 전달하는 역할을 담당합니다. 또한 브로커는 **일반적으로 '카프카'라고 불리는 시스템을 말합니다.** 프로듀서와 컨슈머는 별도의 애플리케이션으로 구성되는 반면, 브로커는 카프카 자체이기 때문입니다. 따라서 '카프카를 구성한다' 혹은 '카프카를 통해 메시지를 전달한다'에서 카프카는 브로커를 의미합니다.

### 카프카와 Zookeeper 관계

분산 application을 사용하게 되면, 관리를 위한 안정적인 코디네이션이 추가로 필요하게 됩니다.

안정적인 코디네이션 서비스로 검증된 주키퍼를 많이 사용합니다.

**주키퍼**는 분산 application을 위한 코디네이션 시스템 입니다. 분산 application이 안정적인 서비스를 할 수 있도록 분산되어 있는 각 application의 정보를 중앙에 집중시키고 구성관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공합니다.

**상태 정보**들은 주키퍼의 지노드(znode)라고 불리는 곳에 key-value 형태로 저장하며, 지노드에 저장된 것을 이용하여 분산 application들은 서로 데이터를 주고 받게되는 구조 입니다.

znode를 일반 컴퓨터의 파일이나 폴더 개념으로 생각하시면 편합니다. 우리가 알고 있는 일반적인 디렉토리와 비슷한 형태로서 자식노드를 가지고 있는 계층형 구조로 구성되어 있습니다.

주키퍼는 좀 더 신뢰성 있는 서비스를 위해 앙상블(클러스터)이라는 호스트 세트를 구성할 수 있습니다. 앙상블로 구성되어 있는 주키퍼는 과반수 방식에 따라 살아 있는 노드 수가 **과반수 이상** 유지된다면, 지속적인 서비스가 가능합니다.

- Case1. 주키퍼 클러스터 3대 구성
  - 노드 1대 다운: 과반수 유지 이므로 서비스 가능
  - 노드 2대 다운: 과반수가 유지되지 않아 서비스 불가
- Case2. 주키퍼 클러스터 5대 구성
  - 노드 2대 다운: 과반수 유지 이므로 서비스 가능

### 카프카의 토픽

**토픽(Topic)은 카프카 메세지를 구분하는 논리적인 단위로,** 동일한 토픽의 메세지들은 논리적으로 같은 문맥(context)을 가집니다. 예를들어, 주문에 관한 내용을 담고 있는 메세지를 발행하고, 소비하기 위해서 우리는 order라는 토픽을 생성하고 이 토픽을 기준으로 메세지를 발행, 소비를 할 수 있습니다.

이처럼 토픽은 논리적인 단위이자 메세지의 흐름 단위라고 설명되기도 합니다. 그렇기 때문에 토픽을 설계할 때는 메세지의 논리적인 구분을 명확하게 해야 합니다.

쉽게, 카프카에선 **메시지 피드들을 토픽으로 구분**한다. 토픽은 데이터가 저장되는 공간이며, 데이터베이스의 테이블과 유사하다고 생각하면 된다. 각 토픽의 이름은 카프카 내에서 고유하다.

### 카프카의 파티션

논리적인 단위인 카프카 토픽을 기준으로 발행되는 메세지들은 **브로커 내부의 물리적 단위인 카프카 파티션(Partition)으로 나뉩니다**. 즉, 모든 토픽은 각각 대응하는 하나 이상의 파티션이 브로커에 구성되고, 발행되는 토픽 메세지들은 파티션들에 나뉘어 저장됩니다.

쉽게, 병렬 처리 및 성능 향상을 위해 **하나의 토픽을 여러 개로 나눈 것**을 의미한다. 토픽을 여러 파티션으로 나누면 분산 처리가 가능하며, 나뉜 파티션 수만큼 컨슈머를 연결할 수도 있다.

위 사진처럼 하나의 토픽에 여러 파티션을 구성하는 가장 큰 이유는 **분산 처리를 통한 성능 향상에 있습니다.** 카프카는 하나의 토픽에 대해 여러 프로듀서가 발행할 수 있고, 여러 컨슈머가 구독할 수 있습니다. 그렇기에 **토픽을 하나의 파티션으로 구성하면** **무수한 발행, 구독 요청을 하나의 파티션에 처리해야 합니다.** 물론 카프카는 하나의 파티션으로도 충분한 성능을 발휘할 수 있지만, 일반적으로 **2개 이상의 파티션**을 **서로 다른 브로커에 병렬 구성**하여 **요청의 부하를 분산**시켜 줍니다. 이에 따라 자연스럽게 해당 토픽에 관한 성능도 향상 시킬 수 있습니다.

이외에도 파티션의 가장 큰 특징은 **하나의 파티션 내에서는 메세지 순서가 보장**되는 것 입니다. 즉, 파티션은 메세지 순서 보장의 단위로써, 각 파티션의 메세지는 발행되는 순서대로 구독할 수 있습니다. 따라서 **하나의 토픽**이 **여러 파티션으로 구성되는 경우**, 토픽 단위의 메세지 **순서는 보장할 수 없습니다.** 이는 파티션 내부에서 순서는 보장되지만 **파티션 간의 순서는 보장되지 않기 때문입니다**.

### 파티션 복제 (Partition replication)

하나의 토픽(논리)은 하나 이상의 파티션(물리)으로 구성됩니다. 여기에서 나아가 카프카는 서비스의 안정성과 장애 수용 (Fault-Tolerance)에 관한 요소로 파티션의 복제(Replica) 기능을 제공합니다.

**하나의 파티션에는 1개의 리터 레플리카와 그 외 0개 이상의 팔로워 레플리카로 구성됩니다**. 리더 레플리카는 파티션의 모든 쓰기, 읽기 작업을 담당합니다. 반대로 팔로워 레플리카는 리더 레플리카로 쓰인 메세지들을 그대로 복제하고, 만약 **리더 레플리카에 장애가 발생하는 경우, 리더 자리를 승계 받을 준비를 합니다.**

참고로 승계 받을 준비가 된 즉, 리더 레플리카의 메세지를 적절하게 복제하여 리더 레플리카와 동기화 된 레플리카들의 그룹을 **ISR(In-Sync Replica)**라고 합니다.

파티션의 레플리카 수는 **복제 계수(Replication factor)**를 통해 결정되는데, 만약 복제 계수가 1이라면 파티션은 리더 레플리카로만 구성됩니다. 이때, 파티션과 리더 레플리카는 별개인 것이 아니라 동일한 것으로 볼 수 있습니다. 즉, 일반적으로 말하는 '물리적인 파티션'은 리더 레플리카를 이야기한다고 할 수 있습니다. 나아가 복제 계수가 2개 이상이라면 해당 파티션은 1개의 리더 레플리카와 1개 이상의 팔로어 레플리카로 구성됩니다. 이 경우 **모든 레플리카들은 서로 다른 브로커에 구성됩니다.** 만약 같은 파티션의 레플리카가 동일한 브로커에 구성되는 경우에는 에러가 발생합니다.

이처럼 파티션의 레플리카들은 언제 발생할지 모르는 장애에 대비하여 데이터 유실을 방지하고, 지속적인 서비스를 제공하기 위해 구성됩니다.

### **Kafka 주요 개념**

- Producer와 Consumer의 분리
- Producer와 Consumer는 완전 별개로 동작한다.
- Producer는 Broker의 Topic에 메시지를 게시하기만 한다.
- Consumer는 Broker의 특정 Topic에서 메세지를 가져와 처리하기만 한다.
- Push와 Pull 모델
- 소비된 메세지 추적(Commit과 Offset)
- Consumer Group
- 메시지(이벤트) 전달 컨셉
